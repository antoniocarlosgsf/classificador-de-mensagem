{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Antonio Anderson de Araújo Julião\n",
    "\n",
    "Nome: João Pedro Sardou de Oliveira\n",
    "\n",
    "Nome: Antonio Carlos Gomes dos Santos Filho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Users\\ander\\Desktop\\Material do Semestre\\Ciência de Dados\\2024.1\\Projetos\\Projeto 1\\Repositório\\classificador-de-mensagem\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados manualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>While not specifically designed for file trans...</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This matrix is closely linked to a Role-Based ...</td>\n",
       "      <td>HG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Although Java is a general-purpose programming...</td>\n",
       "      <td>HG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In the following decades, hacking grew in popu...</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>net (network service providers, and so on).</td>\n",
       "      <td>HG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence target\n",
       "0  While not specifically designed for file trans...     AI\n",
       "1  This matrix is closely linked to a Role-Based ...     HG\n",
       "2  Although Java is a general-purpose programming...     HG\n",
       "3  In the following decades, hacking grew in popu...     AI\n",
       "4        net (network service providers, and so on).     HG"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('dados_treino_TRIO_joaopso2.csv')\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Design patterns provide a common language and ...</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The loop  is  the  programming language  struc...</td>\n",
       "      <td>HG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In the following decades, researchers continue...</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is continued until the partition size is ...</td>\n",
       "      <td>HG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Polymorphism is a concept in object-oriented p...</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence target\n",
       "0  Design patterns provide a common language and ...     AI\n",
       "1  The loop  is  the  programming language  struc...     HG\n",
       "2  In the following decades, researchers continue...     AI\n",
       "3  This is continued until the partition size is ...     HG\n",
       "4  Polymorphism is a concept in object-oriented p...     AI"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('dados_teste_TRIO_joaopso2.csv')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "AI    793\n",
       "HG    677\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "AI    334\n",
       "HG    296\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo desenvolvido nesse projeto estuda uma base de dados que contém textos gerados por Humanos e por Inteligência Artificial. Dessa maneira, as classificações desses textos tem como base dois grupos:\n",
    "\n",
    "* AI: Texto gerado por Inteligência Artificial.\n",
    "* HG: Texto gerado por Humano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento de Dados:\n",
    "\n",
    "Antes de iniciarmos as classificações, é fundamental uma preparação dos dados visando um melhor rendimento nas próximas etapas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpeza de Dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/library/re.html#\n",
    "import re \n",
    "import unidecode\n",
    "\n",
    "def cleanup(text):\n",
    "    \n",
    "    #Retirar pontuações do texto\n",
    "    pontuacao = '[´\"!-.:1234567890?;$/'']' \n",
    "    pattern = re.compile(pontuacao)\n",
    "    texto_limpo = re.sub(pattern, '', text)\n",
    "    \n",
    "    #Retirar acentos do texto\n",
    "    texto_limpo = unidecode.unidecode(texto_limpo)\n",
    "    return texto_limpo  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(texto):\n",
    "    \n",
    "    # Converter letras maiúsculas para minúsculas\n",
    "    texto = texto.lower()\n",
    "    palavras = texto.split()\n",
    "\n",
    "    # Lista para armazenar os bigramas\n",
    "    bigramas = []\n",
    "\n",
    "    # Loop para criar bigramas por meio de uma lista de palavras\n",
    "    for i in range(len(palavras) - 1):\n",
    "        bigrama = palavras[i] + \" \" + palavras[i + 1]\n",
    "        bigramas.append(bigrama)\n",
    "\n",
    "    return bigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ander\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('English')\n",
    "stop_words.append('')\n",
    "stop_words = list(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover palavras irrelevantes\n",
    "\n",
    "def stop_word(lista_texto):   \n",
    "    new_list = list()\n",
    "    for palavra in lista_texto:\n",
    "        if palavra not in stop_words:\n",
    "            new_list.append(palavra)\n",
    "\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduzir as palavras à sua forma raiz ou base \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "def stemming(lista_texto):\n",
    "    stemmer = SnowballStemmer('portuguese')\n",
    "    new_list = list()\n",
    "    for palavra in lista_texto:\n",
    "        new_list.append(stemmer.stem(palavra))\n",
    "    \n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converte o DataFrame em string\n",
    "\n",
    "def to_text(data):\n",
    "    texto = ''\n",
    "    for frase in data.sentence:\n",
    "        texto += frase + \" \" \n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executa as funções de limpeza no DataFrame\n",
    "\n",
    "def run(texto):\n",
    "    texto = to_text(texto)\n",
    "    texto = cleanup(texto)\n",
    "    texto = tokenize(texto)\n",
    "    texto = stop_word(texto)\n",
    "    texto = stemming(texto)\n",
    "    series_texto = pd.Series(texto, dtype='object')\n",
    "    return series_texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executa todas as funções de limpeza para uma string\n",
    "\n",
    "def run2(texto):\n",
    "    texto = cleanup(texto)\n",
    "    texto = tokenize(texto)\n",
    "    texto = stop_word(texto)\n",
    "    texto = stemming(texto)\n",
    "    series_texto = pd.Series(texto, dtype='object')\n",
    "    return series_texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Classificação dos grupos\n",
    "\n",
    "* O modelo necessita ser treinado por meio de um conjunto de dados rotulados. A nossa situação é composta de um conjunto de dados que consiste em textos gerados por Humanos ou por Inteligência Artificiais, as quais são agrupadas nas seguintes categorias: HG e AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "HG = train.loc[train.target == 'HG',:]\n",
    "AI = train.loc[train.target == 'AI',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequências Relativas:\n",
    "\n",
    "tabela_relativa_HG = run(HG).value_counts(True)\n",
    "tabela_relativa_AI = run(AI).value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequências Absolutas\n",
    "\n",
    "tabela_absoluta_HG = run(HG).value_counts()\n",
    "tabela_absoluta_AI = run(AI).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequências da Base de Treino\n",
    "\n",
    "tabela_train = run(train)\n",
    "tabela_train_relativa = tabela_train.value_counts(True)\n",
    "tabela_train_absoluta = tabela_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treino sem repetição de palavras\n",
    "\n",
    "tabela_train_sem_repetir = set(tabela_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Probabilidades a Priori (Prior Probability): Para cada grupo (HG e AI), calculamos a probabilidade a priori, ou seja, a probabilidade de um texto pertencer a cada um desses grupos. Isso é feito contando quantos textos existem em cada grupo e dividindo pelo total de textos.\n",
    "\n",
    "$$P(HG) = \\frac{Número De Palavras HG}{Número De Palavras Totais}$$\n",
    "\n",
    "\n",
    "$$P(AI) = \\frac{Número De Palavras AI}{Número De Palavras Totais}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_HG = tabela_absoluta_HG.sum()/tabela_train_absoluta.sum()\n",
    "P_AI = tabela_absoluta_AI.sum()/tabela_train_absoluta.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Probabilidades Condicionais (Likelihood): Para cada palavra (característica) no conjunto de dados, calculamos a probabilidade condicional de a palavra aparecer em um texto de cada grupo. Essas probabilidades condicionais são calculadas separadamente para cada grupo.\n",
    "\n",
    "$$P(Palavra|HG) = \\frac{P(HG|Palavra) P(Palavra)}{P(HG)}$$\n",
    "\n",
    "\n",
    "$$P(Palavra|AI) = \\frac{P(AI|Palavra) P(Palavra)}{P(AI)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Probabilidade a Posteriori (Posterior Probability): Usando o teorema de Bayes, combinamos as probabilidades a priori e as probabilidades condicionais para calcular a probabilidade a posteriori de um novo texto pertencer a cada um dos dois grupos.\n",
    "\n",
    "Por exemplo, para um novo comentário, podemos calcular a probabilidade a posteriori de pertencer ao HG e ao AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_prob(frase ,tabela_absoluta, tabela_train_sem_repetir, prob, alpha=0.05):\n",
    "    \n",
    "    prob_condicional = 1\n",
    "    for palavra in frase:\n",
    "        if palavra in tabela_absoluta:    \n",
    "            #Suavização de Laplace\n",
    "            p = (tabela_absoluta[palavra] + alpha)/ (tabela_absoluta.sum() + len(tabela_train_sem_repetir) * alpha) \n",
    "            prob_condicional *= p * prob\n",
    "            \n",
    "        else:\n",
    "            #Suavização de Laplace\n",
    "            q =(0 + alpha)/ (tabela_absoluta.sum() + len(tabela_train_sem_repetir) * alpha)\n",
    "            prob_condicional *= q * prob\n",
    "            \n",
    "    return prob_condicional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Classificação de Novos Comentários:\n",
    "\n",
    "Após o modelo ser treinado, ele pode ser usado para classificar novos textos em uma das duas categorias com base nas probabilidades calculadas.\n",
    "\n",
    "\n",
    "* Classificação: Finalmente, classificamos um novo texto no grupo com a maior probabilidade a posteriori. O grupo com a probabilidade mais alta é considerado a categoria prevista para o comentário.\n",
    "\n",
    "Por exemplo, se a probabilidade a posteriori mais alta for a do AI, o novo texto será classificado como pertencente ao AI, indicando que ele contém sentimentos relacionados a textos gerados por Inteligência Artificial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificador_de_frases(data):\n",
    "    \n",
    "    resultado = []\n",
    "\n",
    "    for frase in data.sentence:\n",
    "        \n",
    "        frase = run2(frase) # Aplica a função run2 que limpa a frase\n",
    "\n",
    "        aux = []\n",
    "        probFrase_dado_HG = 1 \n",
    "        probFrase_dado_AI = 1\n",
    "        \n",
    "        #Calculamos a probabilidade posteriori de cada frase para cada target\n",
    "        \n",
    "        probFrase_dado_HG = calcula_prob(frase,tabela_absoluta_HG,tabela_train_sem_repetir,P_HG)\n",
    "        probFrase_dado_AI = calcula_prob(frase,tabela_absoluta_AI,tabela_train_sem_repetir,P_AI) \n",
    "        \n",
    "        #Verificamos o maior termo e adicionamos seu respectivo valor semântico na lista\n",
    "        aux.append(probFrase_dado_HG)\n",
    "        aux.append(probFrase_dado_AI)\n",
    "        aux = sorted(aux, reverse=True)\n",
    "        \n",
    "        if aux[0] == probFrase_dado_HG:\n",
    "            resultado.append(\"HG\")\n",
    "        else:\n",
    "            resultado.append(\"AI\")\n",
    "            \n",
    "        \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_teste = classificador_de_frases(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Bot</th>\n",
       "      <th>AI</th>\n",
       "      <th>HG</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AI</th>\n",
       "      <td>0.471429</td>\n",
       "      <td>0.058730</td>\n",
       "      <td>0.530159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG</th>\n",
       "      <td>0.225397</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.469841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0.696825</td>\n",
       "      <td>0.303175</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Bot           AI        HG       All\n",
       "target                              \n",
       "AI      0.471429  0.058730  0.530159\n",
       "HG      0.225397  0.244444  0.469841\n",
       "All     0.696825  0.303175  1.000000"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Bot'] = lista_teste\n",
    "verificacao = pd.crosstab(test.target, test.Bot, normalize = True, margins = True)\n",
    "verificacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.92215568862275"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verdadeiros Positivos\n",
    "\n",
    "verdadeiro_positivo = (verificacao[\"AI\"][\"AI\"]/verificacao[\"All\"][\"AI\"])*100\n",
    "verdadeiro_positivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.972972972972975"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Falsos Positivos\n",
    "\n",
    "falso_positivo = (verificacao[\"AI\"][\"HG\"]/verificacao[\"All\"][\"HG\"])*100\n",
    "falso_positivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.027027027027025"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verdadeiros Negativos\n",
    "\n",
    "verdadeiro_negativo = 100 - falso_positivo\n",
    "verdadeiro_negativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.077844311377248"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Falsos Negativos\n",
    "\n",
    "falso_negativo = 100 - verdadeiro_positivo\n",
    "falso_negativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.58730158730158"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Acurácia\n",
    "\n",
    "acuracia = ((verificacao[\"AI\"][\"AI\"] + verificacao['HG'][\"HG\"]))*100\n",
    "acuracia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CONSIDEROU mais de duas categorias na variável Target e INCREMENTOU a quantidade de notícias, mantendo pelo menos 250 notícias por categoria (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* Para Target com duas categorias: CRIOU pelo menos quatro categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto (pelo menos dois cenários, exceto aqueles já apresentados em sala pelos professores: por exemplo, filtro de spam)\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item Qualidade do Classificador a partir de novas separações das Notícias entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
