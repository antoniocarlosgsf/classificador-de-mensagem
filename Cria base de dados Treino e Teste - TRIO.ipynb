{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [**About Dataset - Kaggle**](https://www.kaggle.com/datasets/mahdimaktabdar/chatgpt-classification-dataset)\n",
    "\n",
    "We have compiled a dataset that consists of textual articles including common terminology, concepts and definitions in the field of computer science, artificial intelligence, and cyber security. This dataset consists of both human-generated text and OpenAI’s ChatGPT-generated text. Human-generated answers were collected from different computer science dictionaries and encyclopedias including “The Encyclopedia of Computer Science and Technology” and \"Encyclopedia of Human-Computer Interaction\".\n",
    "\n",
    "AI-generated content in our dataset was produced by simply posting questions to OpenAI’s ChatGPT and manually documenting the resulting responses. A rigorous data-cleaning process has been performed to remove unwanted Unicode characters, styling and formatting tags. To structure our dataset for binary classification, we combined both AI-generated and Human-generated answers into a single column and assigned appropriate labels to each data point (Human-generated = 0 and AI-generated = 1).\n",
    "\n",
    "This constructs our sentence-level dataset (sentence_level_data.csv) which consists of a total of 7344 entries (4008 AI-generated and 3336 Human-generated).\n",
    "\n",
    "We appreciate it, if you cite the following article if you happen to use this dataset in any scientific publication:\n",
    "\n",
    "Maktab Dar Oghaz, M., Dhame, K., Singaram, G., & Babu Saheer, L. (2023). Detection and Classification of ChatGPT Generated Contents Using Deep Transformer Models. IEEEAccess.\n",
    "https://www.techrxiv.org/articles/preprint/Detection_and_Classification_of_ChatGPT_Generated_Contents_Using_Deep_Transformer_Models/23895951"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma string em inteiro\n",
    "def nome_para_inteiro(nome):\n",
    "    nome = nome.upper()  # Converter para maiúsculas para tratar maiúsculas e minúsculas da mesma forma\n",
    "    valor_inteiro = 0\n",
    "    \n",
    "    for letra in nome:\n",
    "        # Verificar se a letra está no alfabeto (A a Z)\n",
    "        if 'A' <= letra <= 'Z':\n",
    "            valor_inteiro += ord(letra) - ord('A') + 1  # Valor de 'A' é 1, 'B' é 2, ..., 'Z' é 26\n",
    "    \n",
    "    return valor_inteiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler o arquivo de dados \n",
    "dados = pd.read_csv('sentence_level_data.csv', encoding='utf-8-sig').iloc[:,1:]\n",
    "\n",
    "#Human-generated = 0 and AI-generated = 1\n",
    "dados.loc[dados['class']==0,'target'] = 'HG'\n",
    "dados.loc[dados['class']==1,'target'] = 'AI'\n",
    "dados.drop(columns=['class'], inplace=True)\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome = input(\"Digite seu username do Insper: \")\n",
    "valor_inteiro = nome_para_inteiro(nome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valor_inteiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embaralhar as linhas do conjunto de dados\n",
    "dados_embaralhados = dados.sample(frac=2100/dados.shape[0], random_state=valor_inteiro)\n",
    "dados_embaralhados.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar os dados de treino e teste \n",
    "X = dados_embaralhados.sentence\n",
    "y = dados_embaralhados.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=valor_inteiro)\n",
    "\n",
    "dados_treino = pd.concat([X_train, y_train],axis=1)\n",
    "dados_treino.columns = ['sentence', 'target']\n",
    "dados_teste = pd.concat([X_test, y_test],axis=1)\n",
    "dados_teste.columns = ['sentence', 'target']\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(dados_treino.target.value_counts(True))\n",
    "print(dados_teste.target.value_counts(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar os dados de treino e teste em arquivos CSV\n",
    "nome_arquivo_treino = 'dados_treino_TRIO_'+nome+'.csv'\n",
    "nome_arquivo_teste = 'dados_teste_TRIO_'+nome+'.csv'\n",
    "\n",
    "dados_treino.to_csv(nome_arquivo_treino,index = False, header=True)\n",
    "dados_teste.to_csv(nome_arquivo_teste, index=False)#, engine='xlsxwriter')\n",
    "\n",
    "print(f\"Dados de treino e teste foram salvos em '{nome_arquivo_treino}' e '{nome_arquivo_teste}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMANDO QUE DEVE COLOCAR NO TEMPLATE Projeto1_Template.ipynb para LER a base de dados TREINO\n",
    "# Faça adaptações digitando o nome (username) considerado\n",
    "pd.read_csv('dados_treino_TRIO_'+nome+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# COMANDO QUE DEVE COLOCAR NO TEMPLATE Projeto1_Template.ipynb para LER a base de dados TESTE\n",
    "# Faça adaptações digitando o nome (username) considerado\n",
    "pd.read_csv('dados_teste_TRIO_'+nome+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
